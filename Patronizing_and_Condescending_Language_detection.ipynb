{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674fe68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Bichu\n",
      "[nltk_data]     George\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import nltk \n",
    "nltk.download('stopwords')                 # download the stopwords from NLTK\n",
    "import numpy as np\n",
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "import os\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt            # library for visualization\n",
    "import seaborn as sns\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import collections\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, jaccard_score, f1_score, precision_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccc8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DontPatronizeMe:\n",
    "    \n",
    "    def __init__(self, train_path):\n",
    "        \n",
    "        self.train_path = train_path\n",
    "#         self.test_path = test_path\n",
    "        self.train_task1_df = None\n",
    "        self.train_task2_df = None\n",
    "#         self.test_set = None\n",
    "        \n",
    "    \n",
    "    def load_task1(self):\n",
    "        \n",
    "        rows=[]\n",
    "        with open(os.path.join(self.train_path, 'dontpatronizeme_pcl.tsv')) as f:\n",
    "            for line in f.readlines()[4:]:\n",
    "                par_id=line.strip().split('\\t')[0]\n",
    "                art_id = line.strip().split('\\t')[1]\n",
    "                keyword=line.strip().split('\\t')[2]\n",
    "                country=line.strip().split('\\t')[3]\n",
    "                t=line.strip().split('\\t')[4].lower()\n",
    "                l=line.strip().split('\\t')[-1]\n",
    "                if l=='0' or l=='1':\n",
    "                    lbin=0\n",
    "                else:\n",
    "                    lbin=1\n",
    "                rows.append({'par_id':par_id,\n",
    "                             'art_id':art_id,\n",
    "                             'keyword':keyword,\n",
    "                             'country':country,\n",
    "                             'text':t, \n",
    "                             'label':lbin, \n",
    "                             'orig_label':l\n",
    "                             })\n",
    "                df=pd.DataFrame(rows, columns=['par_id', 'art_id', 'keyword', 'country', 'text', 'label', 'orig_label']) \n",
    "                self.train_task1_df = df\n",
    "        return df\n",
    "    \n",
    "    def load_task2(self, return_one_hot=True):\n",
    "# Reads the data for task 2 and present it as paragraphs with binarized labels (a list with seven positions, \"activated or not (1 or 0)\",\n",
    "# depending on wether the category is present in the paragraph).\n",
    "# It returns a pandas dataframe with paragraphs and list of binarized labels.\n",
    "        tag2id = {\n",
    "                'Unbalanced_power_relations':0,\n",
    "                'Shallow_solution':1,\n",
    "                'Presupposition':2,\n",
    "                'Authority_voice':3,\n",
    "                'Metaphors':4,\n",
    "                'Compassion':5,\n",
    "                'The_poorer_the_merrier':6\n",
    "                }\n",
    "        #print('Map of label to numerical label:')\n",
    "        #print(tag2id)\n",
    "        data = collections.defaultdict(list)\n",
    "        with open (os.path.join(self.train_path, 'dontpatronizeme_categories.tsv')) as f:\n",
    "            for line in f.readlines()[4:]:\n",
    "                par_id=line.strip().split('\\t')[0]\n",
    "                art_id = line.strip().split('\\t')[1]\n",
    "                text=line.split('\\t')[2].lower()\n",
    "                keyword=line.split('\\t')[3]\n",
    "                country=line.split('\\t')[4]\n",
    "                start=line.split('\\t')[5]\n",
    "                finish=line.split('\\t')[6]\n",
    "                text_span=line.split('\\t')[7]\n",
    "                label=line.strip().split('\\t')[-2]\n",
    "                num_annotators=line.strip().split('\\t')[-1]\n",
    "                labelid = tag2id[label]\n",
    "                if not label in data[(par_id, art_id, text, keyword, country)]:\n",
    "                    data[(par_id,art_id, text, keyword, country)].append(label)\n",
    "\n",
    "        par_ids=[]\n",
    "        art_ids=[]\n",
    "        pars=[]\n",
    "        keywords=[]\n",
    "        countries=[]\n",
    "        labels=[]\n",
    "\n",
    "        for par_id, art_id, par, kw, co in data.keys():\n",
    "            par_ids.append(par_id)\n",
    "            art_ids.append(art_id)\n",
    "            pars.append(par)\n",
    "            keywords.append(kw)\n",
    "            countries.append(co)\n",
    "\n",
    "        for label in data.values():\n",
    "            labels.append(label)\n",
    "        if return_one_hot:\n",
    "            labels = MultiLabelBinarizer().fit_transform(labels)\n",
    "        df = pd.DataFrame(list(zip(par_ids, \n",
    "                                    art_ids, \n",
    "                                    pars, \n",
    "                                    keywords,\n",
    "                                    countries, \n",
    "                                    labels)), columns=['par_id',\n",
    "                                                        'art_id', \n",
    "                                                        'text', \n",
    "                                                        'keyword',\n",
    "                                                        'country', \n",
    "                                                        'label',\n",
    "                                                    ])\n",
    "        self.train_task2_df = df\n",
    "        return df\n",
    "        \n",
    "    def load_test(self):\n",
    "        #self.test_df = [line.strip() for line in open(self.test_path)]\n",
    "        rows=[]\n",
    "        with open(os.path.join(self.train_path,'task4_test.tsv')) as f:\n",
    "            for line in f.readlines()[0:]:\n",
    "                t=line.strip().split('\\t')[4].lower()\n",
    "                rows.append(t)\n",
    "        self.test_set = rows\n",
    "        return rows\n",
    "    \n",
    "    def load_test_index(self):\n",
    "        #self.test_df = [line.strip() for line in open(self.test_path)]\n",
    "        rows=[]\n",
    "        with open(os.path.join(self.train_path,'task4_test.tsv')) as f:\n",
    "            for line in f.readlines()[0:]:\n",
    "                t=line.strip().split('\\t')[0]\n",
    "                rows.append(t)\n",
    "        self.test_set = rows\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9805a55d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A=DontPatronizeMe(\"D:/NLP_Competetion_new/dontpatronizeme_v1.4\")\n",
    "data=A.load_task1()\n",
    "\n",
    "data_task2=A.load_task2()\n",
    "test_data = A.load_test()\n",
    "test_data_index = A.load_test_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9036dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>text</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>@@14767805</td>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279</td>\n",
       "      <td>@@7896098</td>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8330</td>\n",
       "      <td>@@17252299</td>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4063</td>\n",
       "      <td>@@3002894</td>\n",
       "      <td>\"budding chefs , like \"\" fred \"\" , \"\" winston ...</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ie</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4089</td>\n",
       "      <td>@@25597822</td>\n",
       "      <td>\"in a 90-degree view of his constituency , one...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>pk</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>873</td>\n",
       "      <td>@@20374243</td>\n",
       "      <td>citing the fact that these kids who died at go...</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>sg</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>10070</td>\n",
       "      <td>@@15573661</td>\n",
       "      <td>fern ? ndez was a well-known philanthropist wh...</td>\n",
       "      <td>disabled</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>6484</td>\n",
       "      <td>@@2559173</td>\n",
       "      <td>touched much by their plight , commanding offi...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>lk</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>6249</td>\n",
       "      <td>@@1947926</td>\n",
       "      <td>she reiterated her ministry 's commitment to p...</td>\n",
       "      <td>women</td>\n",
       "      <td>gh</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>5149</td>\n",
       "      <td>@@1789214</td>\n",
       "      <td>preaching the sermon , the dean of the st. pet...</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>gh</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    par_id      art_id                                               text  \\\n",
       "0     4046  @@14767805  we also know that they can benefit by receivin...   \n",
       "1     1279   @@7896098  pope francis washed and kissed the feet of mus...   \n",
       "2     8330  @@17252299  many refugees do n't want to be resettled anyw...   \n",
       "3     4063   @@3002894  \"budding chefs , like \"\" fred \"\" , \"\" winston ...   \n",
       "4     4089  @@25597822  \"in a 90-degree view of his constituency , one...   \n",
       "..     ...         ...                                                ...   \n",
       "988    873  @@20374243  citing the fact that these kids who died at go...   \n",
       "989  10070  @@15573661  fern ? ndez was a well-known philanthropist wh...   \n",
       "990   6484   @@2559173  touched much by their plight , commanding offi...   \n",
       "991   6249   @@1947926  she reiterated her ministry 's commitment to p...   \n",
       "992   5149   @@1789214  preaching the sermon , the dean of the st. pet...   \n",
       "\n",
       "           keyword country                  label  \n",
       "0         hopeless      us  [1, 0, 0, 0, 0, 0, 1]  \n",
       "1          refugee      ng  [0, 0, 0, 0, 1, 0, 0]  \n",
       "2          refugee      ng  [0, 0, 0, 1, 0, 0, 0]  \n",
       "3          in-need      ie  [1, 1, 1, 0, 0, 0, 1]  \n",
       "4         homeless      pk  [0, 0, 0, 0, 0, 0, 1]  \n",
       "..             ...     ...                    ...  \n",
       "988  poor-families      sg  [0, 0, 1, 0, 0, 0, 1]  \n",
       "989       disabled      ng  [0, 0, 0, 0, 0, 0, 1]  \n",
       "990       homeless      lk  [0, 1, 0, 0, 0, 0, 1]  \n",
       "991          women      gh  [0, 0, 0, 0, 0, 0, 1]  \n",
       "992     vulnerable      gh  [1, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[993 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c6010ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id\n",
       "0  t_0\n",
       "1  t_1\n",
       "2  t_2\n",
       "3  t_3\n",
       "4  t_4"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexof_test = pd.DataFrame({'id':test_data_index})\n",
    "indexof_test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b0ca069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the meantime , conservatives are working to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in most poor households with no education chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the real question is not whether immigration i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in total , the country 's immigrant population...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>members of the church , which is part of ken c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                test\n",
       "0  in the meantime , conservatives are working to...\n",
       "1  in most poor households with no education chil...\n",
       "2  the real question is not whether immigration i...\n",
       "3  in total , the country 's immigrant population...\n",
       "4  members of the church , which is part of ken c..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'test':test_data})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33ccb5",
   "metadata": {},
   "source": [
    "### df has test and data has train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a01768bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the meantime , conservatives are working to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in most poor households with no education chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the real question is not whether immigration i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in total , the country 's immigrant population...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>members of the church , which is part of ken c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>in a letter dated thursday to european commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>they discovered that poor families with health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>she married at 19 , to milan ( emil ) badovina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>the united kingdom is n't going to devolve int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>this moral battle informed the recent defectio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     in the meantime , conservatives are working to...\n",
       "1     in most poor households with no education chil...\n",
       "2     the real question is not whether immigration i...\n",
       "3     in total , the country 's immigrant population...\n",
       "4     members of the church , which is part of ken c...\n",
       "...                                                 ...\n",
       "3827  in a letter dated thursday to european commiss...\n",
       "3828  they discovered that poor families with health...\n",
       "3829  she married at 19 , to milan ( emil ) badovina...\n",
       "3830  the united kingdom is n't going to devolve int...\n",
       "3831  this moral battle informed the recent defectio...\n",
       "\n",
       "[3832 rows x 1 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = data[\"text\"]\n",
    "d = df[\"test\"]\n",
    "df[\"text\"] = d\n",
    "df = df.drop(['test'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c6e49032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f8b66348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we 're living in times of absolute insanity , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in libya today , there are countless number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"white house press secretary sean spicer said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>council customers only signs would be displaye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10464</th>\n",
       "      <td>\"sri lankan norms and culture inhibit women fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10465</th>\n",
       "      <td>he added that the afp will continue to bank on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>\"\"\" she has one huge platform , and informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>\"\"\" anja ringgren loven i ca n't find a word t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>\"\"\" guinness world record of 540lbs of 7-layer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10469 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      we 're living in times of absolute insanity , ...\n",
       "1      in libya today , there are countless number of...\n",
       "2      \"white house press secretary sean spicer said ...\n",
       "3      council customers only signs would be displaye...\n",
       "4      \"\"\" just like we received migrants fleeing el ...\n",
       "...                                                  ...\n",
       "10464  \"sri lankan norms and culture inhibit women fr...\n",
       "10465  he added that the afp will continue to bank on...\n",
       "10466  \"\"\" she has one huge platform , and informatio...\n",
       "10467  \"\"\" anja ringgren loven i ca n't find a word t...\n",
       "10468  \"\"\" guinness world record of 540lbs of 7-layer...\n",
       "\n",
       "[10469 rows x 1 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.to_frame()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "59e8b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.concat([df_train, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "91e08659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    in the meantime , conservatives are working to...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.iloc[10469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "578d46f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14301, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b807a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea79cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad56e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730291e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>we 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migrant</td>\n",
       "      <td>in libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigrant</td>\n",
       "      <td>\"white house press secretary sean spicer said ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disabled</td>\n",
       "      <td>council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>refugee</td>\n",
       "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in-need</td>\n",
       "      <td>to bring down high blood sugar levels , insuli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>refugee</td>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>\"\"\" they 're either hopeless for being beaten ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>homeless</td>\n",
       "      <td>nueva era , ilocos norte - no family shall be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in-need</td>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword                                               text  label\n",
       "0   hopeless  we 're living in times of absolute insanity , ...      0\n",
       "1    migrant  in libya today , there are countless number of...      0\n",
       "2  immigrant  \"white house press secretary sean spicer said ...      0\n",
       "3   disabled  council customers only signs would be displaye...      0\n",
       "4    refugee  \"\"\" just like we received migrants fleeing el ...      0\n",
       "5    in-need  to bring down high blood sugar levels , insuli...      0\n",
       "6    refugee  the european union is making an historic mista...      0\n",
       "7   hopeless  \"\"\" they 're either hopeless for being beaten ...      0\n",
       "8   homeless  nueva era , ilocos norte - no family shall be ...      0\n",
       "9    in-need  his spokesman said the kremlin needed more inf...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['art_id'], axis=1)  # dropping unnecesary column\n",
    "data = data.drop(['par_id'], axis=1)  # dropping unnecesary column\n",
    "data = data.drop(['orig_label'], axis=1)  # dropping unnecesary column\n",
    "data = data.drop(['country'], axis=1)  # dropping unnecesary column\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca4dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-9b7a7fe363c1>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.text = data.text.str.replace('[#,@,&]', '')\n",
      "<ipython-input-5-9b7a7fe363c1>:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.text = data.text.str.replace(' \\d+ ','')\n",
      "<ipython-input-5-9b7a7fe363c1>:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.text = data.text.str.replace('w{3}','')\n",
      "<ipython-input-5-9b7a7fe363c1>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.text = data.text.str.replace(\"http\\S+\", \"\")\n",
      "<ipython-input-5-9b7a7fe363c1>:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.text = data.text.str.replace('\\s+', ' ')\n",
      "<ipython-input-5-9b7a7fe363c1>:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.text = data.text.str.replace(r'\\s+[a-zA-Z]\\s+', '')\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(x)\n",
    "\n",
    "\n",
    "def lemmatize(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "#  Preprocess train dataset\n",
    "# remove special characters from text column\n",
    "data.text = data.text.str.replace('[#,@,&]', '')\n",
    "# Remove digits\n",
    "data.text = data.text.str.replace(' \\d+ ','')\n",
    "#Remove www\n",
    "data.text = data.text.str.replace('w{3}','')\n",
    "# remove urls\n",
    "data.text = data.text.str.replace(\"http\\S+\", \"\")\n",
    "# remove multiple spaces with single space\n",
    "data.text = data.text.str.replace('\\s+', ' ')\n",
    "#remove all single characters\n",
    "data.text = data.text.str.replace(r'\\s+[a-zA-Z]\\s+', '')\n",
    "data['tokens'] = data['text'].map(tokenize)\n",
    "data['lemma'] = data['tokens'].map(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4208afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619b208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>we 're living in times of absolute insanity as...</td>\n",
       "      <td>0</td>\n",
       "      <td>[we, re, living, in, times, of, absolute, insa...</td>\n",
       "      <td>we re living in time of absolute insanity a m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migrant</td>\n",
       "      <td>in libya today there are countless number of g...</td>\n",
       "      <td>0</td>\n",
       "      <td>[in, libya, today, there, are, countless, numb...</td>\n",
       "      <td>in libya today there are countless number of g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigrant</td>\n",
       "      <td>\"white house press secretary sean spicer said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[white, house, press, secretary, sean, spicer,...</td>\n",
       "      <td>white house press secretary sean spicer said t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disabled</td>\n",
       "      <td>council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "      <td>[council, customers, only, signs, would, be, d...</td>\n",
       "      <td>council customer only sign would be displayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>refugee</td>\n",
       "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[just, like, we, received, migrants, fleeing, ...</td>\n",
       "      <td>just like we received migrant fleeing el salva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in-need</td>\n",
       "      <td>to bring down high blood sugar levels insulin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[to, bring, down, high, blood, sugar, levels, ...</td>\n",
       "      <td>to bring down high blood sugar level insulin n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>refugee</td>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, european, union, is, making, an, histori...</td>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>\"\"\" they 're either hopeless for being beaten ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[they, re, either, hopeless, for, being, beate...</td>\n",
       "      <td>they re either hopeless for being beaten by10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>homeless</td>\n",
       "      <td>nueva era ilocos norte - no family shall be ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nueva, era, ilocos, norte, no, family, shall,...</td>\n",
       "      <td>nueva era ilocos norte no family shall be home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in-need</td>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "      <td>0</td>\n",
       "      <td>[his, spokesman, said, the, kremlin, needed, m...</td>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword                                               text  label  \\\n",
       "0   hopeless  we 're living in times of absolute insanity as...      0   \n",
       "1    migrant  in libya today there are countless number of g...      0   \n",
       "2  immigrant  \"white house press secretary sean spicer said ...      0   \n",
       "3   disabled  council customers only signs would be displaye...      0   \n",
       "4    refugee  \"\"\" just like we received migrants fleeing el ...      0   \n",
       "5    in-need  to bring down high blood sugar levels insulin ...      0   \n",
       "6    refugee  the european union is making an historic mista...      0   \n",
       "7   hopeless  \"\"\" they 're either hopeless for being beaten ...      0   \n",
       "8   homeless  nueva era ilocos norte - no family shall be ho...      0   \n",
       "9    in-need  his spokesman said the kremlin needed more inf...      0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [we, re, living, in, times, of, absolute, insa...   \n",
       "1  [in, libya, today, there, are, countless, numb...   \n",
       "2  [white, house, press, secretary, sean, spicer,...   \n",
       "3  [council, customers, only, signs, would, be, d...   \n",
       "4  [just, like, we, received, migrants, fleeing, ...   \n",
       "5  [to, bring, down, high, blood, sugar, levels, ...   \n",
       "6  [the, european, union, is, making, an, histori...   \n",
       "7  [they, re, either, hopeless, for, being, beate...   \n",
       "8  [nueva, era, ilocos, norte, no, family, shall,...   \n",
       "9  [his, spokesman, said, the, kremlin, needed, m...   \n",
       "\n",
       "                                               lemma  \n",
       "0  we re living in time of absolute insanity a m ...  \n",
       "1  in libya today there are countless number of g...  \n",
       "2  white house press secretary sean spicer said t...  \n",
       "3  council customer only sign would be displayed ...  \n",
       "4  just like we received migrant fleeing el salva...  \n",
       "5  to bring down high blood sugar level insulin n...  \n",
       "6  the european union is making an historic mista...  \n",
       "7  they re either hopeless for being beaten by10 ...  \n",
       "8  nueva era ilocos norte no family shall be home...  \n",
       "9  his spokesman said the kremlin needed more inf...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86b30d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>we 're living in times of absolute insanity as...</td>\n",
       "      <td>0</td>\n",
       "      <td>[we, re, living, in, times, of, absolute, insa...</td>\n",
       "      <td>we re living in time of absolute insanity a m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migrant</td>\n",
       "      <td>in libya today there are countless number of g...</td>\n",
       "      <td>0</td>\n",
       "      <td>[in, libya, today, there, are, countless, numb...</td>\n",
       "      <td>in libya today there are countless number of g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigrant</td>\n",
       "      <td>\"white house press secretary sean spicer said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[white, house, press, secretary, sean, spicer,...</td>\n",
       "      <td>white house press secretary sean spicer said t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disabled</td>\n",
       "      <td>council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "      <td>[council, customers, only, signs, would, be, d...</td>\n",
       "      <td>council customer only sign would be displayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>refugee</td>\n",
       "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[just, like, we, received, migrants, fleeing, ...</td>\n",
       "      <td>just like we received migrant fleeing el salva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in-need</td>\n",
       "      <td>to bring down high blood sugar levels insulin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[to, bring, down, high, blood, sugar, levels, ...</td>\n",
       "      <td>to bring down high blood sugar level insulin n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>refugee</td>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, european, union, is, making, an, histori...</td>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>\"\"\" they 're either hopeless for being beaten ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[they, re, either, hopeless, for, being, beate...</td>\n",
       "      <td>they re either hopeless for being beaten by10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>homeless</td>\n",
       "      <td>nueva era ilocos norte - no family shall be ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nueva, era, ilocos, norte, no, family, shall,...</td>\n",
       "      <td>nueva era ilocos norte no family shall be home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in-need</td>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "      <td>0</td>\n",
       "      <td>[his, spokesman, said, the, kremlin, needed, m...</td>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword                                               text  label  \\\n",
       "0   hopeless  we 're living in times of absolute insanity as...      0   \n",
       "1    migrant  in libya today there are countless number of g...      0   \n",
       "2  immigrant  \"white house press secretary sean spicer said ...      0   \n",
       "3   disabled  council customers only signs would be displaye...      0   \n",
       "4    refugee  \"\"\" just like we received migrants fleeing el ...      0   \n",
       "5    in-need  to bring down high blood sugar levels insulin ...      0   \n",
       "6    refugee  the european union is making an historic mista...      0   \n",
       "7   hopeless  \"\"\" they 're either hopeless for being beaten ...      0   \n",
       "8   homeless  nueva era ilocos norte - no family shall be ho...      0   \n",
       "9    in-need  his spokesman said the kremlin needed more inf...      0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [we, re, living, in, times, of, absolute, insa...   \n",
       "1  [in, libya, today, there, are, countless, numb...   \n",
       "2  [white, house, press, secretary, sean, spicer,...   \n",
       "3  [council, customers, only, signs, would, be, d...   \n",
       "4  [just, like, we, received, migrants, fleeing, ...   \n",
       "5  [to, bring, down, high, blood, sugar, levels, ...   \n",
       "6  [the, european, union, is, making, an, histori...   \n",
       "7  [they, re, either, hopeless, for, being, beate...   \n",
       "8  [nueva, era, ilocos, norte, no, family, shall,...   \n",
       "9  [his, spokesman, said, the, kremlin, needed, m...   \n",
       "\n",
       "                                               lemma  \n",
       "0  we re living in time of absolute insanity a m ...  \n",
       "1  in libya today there are countless number of g...  \n",
       "2  white house press secretary sean spicer said t...  \n",
       "3  council customer only sign would be displayed ...  \n",
       "4  just like we received migrant fleeing el salva...  \n",
       "5  to bring down high blood sugar level insulin n...  \n",
       "6  the european union is making an historic mista...  \n",
       "7  they re either hopeless for being beaten by10 ...  \n",
       "8  nueva era ilocos norte no family shall be home...  \n",
       "9  his spokesman said the kremlin needed more inf...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893cd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labels = data['label']\n",
    "data_para = data['lemma']\n",
    "vectorizer = TfidfVectorizer(use_idf=True,stop_words=stopwords.words('english'), min_df=7, lowercase=True, ngram_range=(1, 2))\n",
    "X=vectorizer.fit_transform(data_para)\n",
    "processed_features = vectorizer.fit_transform(data_para).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5c819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10469, 5924)\n",
      "(10469, 5924)\n"
     ]
    }
   ],
   "source": [
    "print(processed_features.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0300f0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10469, 5924)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = processed_features[0:10469,:]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f04f03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5924)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = processed_features[10469:,:]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6908000",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a5452a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.57"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3828/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb7f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "log_class=LogisticRegression(class_weight='balanced')\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de8a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "10.0 **np.arange(-2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9115d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0321ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, \n",
    "                                                    data['label'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state = 42,stratify=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185afb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf=GridSearchCV(log_class,grid,cv=10,n_jobs=-1,scoring='f1_macro')\n",
    "log_class=LogisticRegression(class_weight='balanced')\n",
    "log_class.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f3b4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1653  242]\n",
      " [  84  115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91      1895\n",
      "           1       0.32      0.58      0.41       199\n",
      "\n",
      "    accuracy                           0.84      2094\n",
      "   macro avg       0.64      0.73      0.66      2094\n",
      "weighted avg       0.89      0.84      0.86      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=log_class.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58c9635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1895\n",
      "           1       0.59      0.07      0.12       199\n",
      "\n",
      "    accuracy                           0.91      2094\n",
      "   macro avg       0.75      0.53      0.53      2094\n",
      "weighted avg       0.88      0.91      0.87      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train,y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e613920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1895\n",
      "           1       0.22      0.23      0.23       199\n",
      "\n",
      "    accuracy                           0.85      2094\n",
      "   macro avg       0.57      0.57      0.57      2094\n",
      "weighted avg       0.85      0.85      0.85      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train,y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01a16239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1895\n",
      "           1       0.38      0.02      0.03       199\n",
      "\n",
      "    accuracy                           0.90      2094\n",
      "   macro avg       0.64      0.51      0.49      2094\n",
      "weighted avg       0.86      0.90      0.86      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train,y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0632cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      1895\n",
      "           1       0.58      0.07      0.13       199\n",
      "\n",
      "    accuracy                           0.91      2094\n",
      "   macro avg       0.75      0.53      0.54      2094\n",
      "weighted avg       0.88      0.91      0.87      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boost = GradientBoostingClassifier()\n",
    "boost.fit(X_train,y_train)\n",
    "y_pred = boost.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13678313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      1895\n",
      "           1       0.31      0.11      0.16       199\n",
      "\n",
      "    accuracy                           0.89      2094\n",
      "   macro avg       0.61      0.54      0.55      2094\n",
      "weighted avg       0.85      0.89      0.87      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag = BaggingClassifier()\n",
    "bag.fit(X_train,y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d124673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1895\n",
      "           1       0.44      0.14      0.21       199\n",
      "\n",
      "    accuracy                           0.90      2094\n",
      "   macro avg       0.68      0.56      0.58      2094\n",
      "weighted avg       0.87      0.90      0.88      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "xb = xgboost.XGBClassifier()\n",
    "xb.fit(X_train,y_train)\n",
    "y_pred = xb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb6f0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight=dict({0:1,1:10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80517d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9476\n",
       "1     993\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5391d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.542799597180261"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9476/993"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d5484",
   "metadata": {},
   "source": [
    "## training for entire train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2374f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_class=LogisticRegression(class_weight='balanced')\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d37ab234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.61408444        nan 0.63178426        nan 0.65800983\n",
      "        nan 0.66174933        nan 0.64542245]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(class_weight='balanced'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GridSearchCV(log_class,grid,cv=10,n_jobs=-1,scoring='f1_macro')\n",
    "clf.fit(train_data, data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3c0c5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "85efb02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575022d",
   "metadata": {},
   "source": [
    "### adding class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "43ebe076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight=dict({0:1,1:9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ca8dd916",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_class=LogisticRegression(class_weight=class_weight)\n",
    "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ea4eaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.64058694        nan 0.64585989        nan 0.66422256\n",
      "        nan 0.65645192        nan 0.6421626 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(class_weight={0: 1, 1: 9}),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GridSearchCV(log_class,grid,cv=10,n_jobs=-1,scoring='f1_macro')\n",
    "clf.fit(train_data, data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "af4a91fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(test_data)\n",
    "np.sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "820332b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8240343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.DataFrame(y_pred.T, columns=['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7fd70dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexof_test['Predictions'] = csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "828bef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>t_3893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>t_3894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>t_3895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>t_3896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>t_3897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Predictions\n",
       "0        t_0            0\n",
       "1        t_1            1\n",
       "2        t_2            0\n",
       "3        t_3            0\n",
       "4        t_4            0\n",
       "...      ...          ...\n",
       "3827  t_3893            0\n",
       "3828  t_3894            1\n",
       "3829  t_3895            0\n",
       "3830  t_3896            0\n",
       "3831  t_3897            0\n",
       "\n",
       "[3832 rows x 2 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e8347c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_TASK_1 = indexof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b4540c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>t_3893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>t_3894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>t_3895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>t_3896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>t_3897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Predictions\n",
       "0        t_0            0\n",
       "1        t_1            1\n",
       "2        t_2            0\n",
       "3        t_3            0\n",
       "4        t_4            0\n",
       "...      ...          ...\n",
       "3827  t_3893            0\n",
       "3828  t_3894            1\n",
       "3829  t_3895            0\n",
       "3830  t_3896            0\n",
       "3831  t_3897            0\n",
       "\n",
       "[3832 rows x 2 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_TASK_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066abe01",
   "metadata": {},
   "source": [
    "## TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d3837677",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_TASK_1['Predictions'].to_csv('C:\\\\Users\\\\Bichu George\\\\Desktop\\\\task1.txt',index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6743bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4d07080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1653  242]\n",
      " [  84  115]]\n",
      "0.8443170964660937\n",
      "F1_score: 0.4136690647482015\n",
      "precision_score: 0.32212885154061627\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "model_L =LogisticRegression(class_weight='balanced')\n",
    "our_lr = model_L.fit(X_train,y_train)\n",
    "predicted_log = model_L.predict(X_test)\n",
    "print(confusion_matrix(y_test,predicted_log))\n",
    "print(accuracy_score(y_test,predicted_log))\n",
    "print(f\"F1_score: {f1_score(y_test,predicted_log)}\")\n",
    "print(f\"precision_score: {precision_score(y_test, predicted_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db0be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72179770",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "        max_depth=1, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "GBC_prediction = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c043190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1846   37]\n",
      " [ 178   33]]\n",
      "0.8973256924546322\n",
      "F1_score: 0.23487544483985762\n",
      "precision_score: 0.4714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,GBC_prediction))\n",
    "print(accuracy_score(y_test,GBC_prediction))\n",
    "print(f\"F1_score: {f1_score(y_test,GBC_prediction)}\")\n",
    "print(f\"precision_score: {precision_score(y_test, GBC_prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b800b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1739  156]\n",
      " [ 104   95]]\n",
      "0.8758357211079274\n",
      "F1_score: 0.42222222222222217\n",
      "precision_score: 0.3784860557768924\n"
     ]
    }
   ],
   "source": [
    "## BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced'),\n",
    "                        n_estimators=100, random_state=0,n_jobs=-1).fit(X_train, y_train)\n",
    "y_test_pred= clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print(accuracy_score(y_test,y_test_pred))\n",
    "print(f\"F1_score: {f1_score(y_test,y_test_pred)}\")\n",
    "print(f\"precision_score: {precision_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c28ec51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1837   58]\n",
      " [ 150   49]]\n",
      "0.9006685768863419\n",
      "F1_score: 0.3202614379084967\n",
      "precision_score: 0.45794392523364486\n"
     ]
    }
   ],
   "source": [
    "## Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0).fit(X_train,y_train)\n",
    "y_test_pred= clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print(accuracy_score(y_test,y_test_pred))\n",
    "print(f\"F1_score: {f1_score(y_test,y_test_pred)}\")\n",
    "print(f\"precision_score: {precision_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a68db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1883    0]\n",
      " [ 208    3]]\n",
      "0.9006685768863419\n",
      "F1_score: 0.02803738317757009\n"
     ]
    }
   ],
   "source": [
    "# Random Forest.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_classifier = RandomForestClassifier(n_estimators=200,random_state=0, class_weight='balanced')\n",
    "random_classifier.fit(X_train, y_train)\n",
    "predictions_forest = random_classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions_forest))\n",
    "print(accuracy_score(y_test,predictions_forest))\n",
    "print(f\"F1_score: {f1_score(y_test,predictions_forest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23f23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1883    0]\n",
      " [ 209    2]]\n",
      "0.9001910219675263\n",
      "F1_score: 0.018779342723004695\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes.\n",
    "naive_model = naive_bayes.MultinomialNB()\n",
    "naive_model.fit(X_train, y_train)\n",
    "predicted_naive=naive_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predicted_naive))\n",
    "print(accuracy_score(y_test,predicted_naive))\n",
    "print(f\"F1_score: {f1_score(y_test,predicted_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "752c8bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1683  200]\n",
      " [ 114   97]]\n",
      "0.8500477554918816\n",
      "F1_score: 0.3818897637795276\n"
     ]
    }
   ],
   "source": [
    "## SVM\n",
    "# SVM C= 1\n",
    "svm_model = SVC(kernel='linear',probability=True, class_weight='balanced', C=1)\n",
    "svm_model.fit(X_train, y_train)\n",
    "predictions_svm = svm_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions_svm))\n",
    "print(accuracy_score(y_test,predictions_svm))\n",
    "\n",
    "print(f\"F1_score: {f1_score(y_test, predictions_svm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48802bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643b252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d297064",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12c1cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>text</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>@@14767805</td>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279</td>\n",
       "      <td>@@7896098</td>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8330</td>\n",
       "      <td>@@17252299</td>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4063</td>\n",
       "      <td>@@3002894</td>\n",
       "      <td>\"budding chefs , like \"\" fred \"\" , \"\" winston ...</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ie</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4089</td>\n",
       "      <td>@@25597822</td>\n",
       "      <td>\"in a 90-degree view of his constituency , one...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>pk</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>873</td>\n",
       "      <td>@@20374243</td>\n",
       "      <td>citing the fact that these kids who died at go...</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>sg</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>10070</td>\n",
       "      <td>@@15573661</td>\n",
       "      <td>fern ? ndez was a well-known philanthropist wh...</td>\n",
       "      <td>disabled</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>6484</td>\n",
       "      <td>@@2559173</td>\n",
       "      <td>touched much by their plight , commanding offi...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>lk</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>6249</td>\n",
       "      <td>@@1947926</td>\n",
       "      <td>she reiterated her ministry 's commitment to p...</td>\n",
       "      <td>women</td>\n",
       "      <td>gh</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>5149</td>\n",
       "      <td>@@1789214</td>\n",
       "      <td>preaching the sermon , the dean of the st. pet...</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>gh</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    par_id      art_id                                               text  \\\n",
       "0     4046  @@14767805  we also know that they can benefit by receivin...   \n",
       "1     1279   @@7896098  pope francis washed and kissed the feet of mus...   \n",
       "2     8330  @@17252299  many refugees do n't want to be resettled anyw...   \n",
       "3     4063   @@3002894  \"budding chefs , like \"\" fred \"\" , \"\" winston ...   \n",
       "4     4089  @@25597822  \"in a 90-degree view of his constituency , one...   \n",
       "..     ...         ...                                                ...   \n",
       "988    873  @@20374243  citing the fact that these kids who died at go...   \n",
       "989  10070  @@15573661  fern ? ndez was a well-known philanthropist wh...   \n",
       "990   6484   @@2559173  touched much by their plight , commanding offi...   \n",
       "991   6249   @@1947926  she reiterated her ministry 's commitment to p...   \n",
       "992   5149   @@1789214  preaching the sermon , the dean of the st. pet...   \n",
       "\n",
       "           keyword country                  label  \n",
       "0         hopeless      us  [1, 0, 0, 0, 0, 0, 1]  \n",
       "1          refugee      ng  [0, 0, 0, 0, 1, 0, 0]  \n",
       "2          refugee      ng  [0, 0, 0, 1, 0, 0, 0]  \n",
       "3          in-need      ie  [1, 1, 1, 0, 0, 0, 1]  \n",
       "4         homeless      pk  [0, 0, 0, 0, 0, 0, 1]  \n",
       "..             ...     ...                    ...  \n",
       "988  poor-families      sg  [0, 0, 1, 0, 0, 0, 1]  \n",
       "989       disabled      ng  [0, 0, 0, 0, 0, 0, 1]  \n",
       "990       homeless      lk  [0, 1, 0, 0, 0, 0, 1]  \n",
       "991          women      gh  [0, 0, 0, 0, 0, 0, 1]  \n",
       "992     vulnerable      gh  [1, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[993 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9b13ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_task2_text = data_task2['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f1c001b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_task2_text = pd.DataFrame(data_task2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1b0964df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"budding chefs , like \"\" fred \"\" , \"\" winston ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"in a 90-degree view of his constituency , one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>citing the fact that these kids who died at go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>fern ? ndez was a well-known philanthropist wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>touched much by their plight , commanding offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>she reiterated her ministry 's commitment to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>preaching the sermon , the dean of the st. pet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    we also know that they can benefit by receivin...\n",
       "1    pope francis washed and kissed the feet of mus...\n",
       "2    many refugees do n't want to be resettled anyw...\n",
       "3    \"budding chefs , like \"\" fred \"\" , \"\" winston ...\n",
       "4    \"in a 90-degree view of his constituency , one...\n",
       "..                                                 ...\n",
       "988  citing the fact that these kids who died at go...\n",
       "989  fern ? ndez was a well-known philanthropist wh...\n",
       "990  touched much by their plight , commanding offi...\n",
       "991  she reiterated her ministry 's commitment to p...\n",
       "992  preaching the sermon , the dean of the st. pet...\n",
       "\n",
       "[993 rows x 1 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d2897e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the meantime , conservatives are working to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in most poor households with no education chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the real question is not whether immigration i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in total , the country 's immigrant population...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>members of the church , which is part of ken c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>in a letter dated thursday to european commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>they discovered that poor families with health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>she married at 19 , to milan ( emil ) badovina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>the united kingdom is n't going to devolve int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>this moral battle informed the recent defectio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     in the meantime , conservatives are working to...\n",
       "1     in most poor households with no education chil...\n",
       "2     the real question is not whether immigration i...\n",
       "3     in total , the country 's immigrant population...\n",
       "4     members of the church , which is part of ken c...\n",
       "...                                                 ...\n",
       "3827  in a letter dated thursday to european commiss...\n",
       "3828  they discovered that poor families with health...\n",
       "3829  she married at 19 , to milan ( emil ) badovina...\n",
       "3830  the united kingdom is n't going to devolve int...\n",
       "3831  this moral battle informed the recent defectio...\n",
       "\n",
       "[3832 rows x 1 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_2 = pd.DataFrame({'text':test_data})\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "130ced1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"budding chefs , like \"\" fred \"\" , \"\" winston ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"in a 90-degree view of his constituency , one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>citing the fact that these kids who died at go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>fern ? ndez was a well-known philanthropist wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>touched much by their plight , commanding offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>she reiterated her ministry 's commitment to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>preaching the sermon , the dean of the st. pet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    we also know that they can benefit by receivin...\n",
       "1    pope francis washed and kissed the feet of mus...\n",
       "2    many refugees do n't want to be resettled anyw...\n",
       "3    \"budding chefs , like \"\" fred \"\" , \"\" winston ...\n",
       "4    \"in a 90-degree view of his constituency , one...\n",
       "..                                                 ...\n",
       "988  citing the fact that these kids who died at go...\n",
       "989  fern ? ndez was a well-known philanthropist wh...\n",
       "990  touched much by their plight , commanding offi...\n",
       "991  she reiterated her ministry 's commitment to p...\n",
       "992  preaching the sermon , the dean of the st. pet...\n",
       "\n",
       "[993 rows x 1 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0da99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "18c4b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all2=pd.concat([data_task2_text, df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a3784dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"budding chefs , like \"\" fred \"\" , \"\" winston ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"in a 90-degree view of his constituency , one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>in a letter dated thursday to european commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>they discovered that poor families with health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>she married at 19 , to milan ( emil ) badovina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>the united kingdom is n't going to devolve int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>this moral battle informed the recent defectio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4825 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     we also know that they can benefit by receivin...\n",
       "1     pope francis washed and kissed the feet of mus...\n",
       "2     many refugees do n't want to be resettled anyw...\n",
       "3     \"budding chefs , like \"\" fred \"\" , \"\" winston ...\n",
       "4     \"in a 90-degree view of his constituency , one...\n",
       "...                                                 ...\n",
       "3827  in a letter dated thursday to european commiss...\n",
       "3828  they discovered that poor families with health...\n",
       "3829  she married at 19 , to milan ( emil ) badovina...\n",
       "3830  the united kingdom is n't going to devolve int...\n",
       "3831  this moral battle informed the recent defectio...\n",
       "\n",
       "[4825 rows x 1 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2c9c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-2c852516f30a>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace('[#,@,&]', '')\n",
      "<ipython-input-29-2c852516f30a>:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace(' \\d+ ','')\n",
      "<ipython-input-29-2c852516f30a>:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace('w{3}','')\n",
      "<ipython-input-29-2c852516f30a>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace(\"http\\S+\", \"\")\n",
      "<ipython-input-29-2c852516f30a>:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace('\\s+', ' ')\n",
      "<ipython-input-29-2c852516f30a>:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace(r'\\s+[a-zA-Z]\\s+', '')\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(x)\n",
    "\n",
    "\n",
    "def lemmatize(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "#  Preprocess train dataset\n",
    "# remove special characters from text column\n",
    "data_task2.text = data_task2.text.str.replace('[#,@,&]', '')\n",
    "# Remove digits\n",
    "data_task2.text = data_task2.text.str.replace(' \\d+ ','')\n",
    "#Remove www\n",
    "data_task2.text = data_task2.text.str.replace('w{3}','')\n",
    "# remove urls\n",
    "data_task2.text = data_task2.text.str.replace(\"http\\S+\", \"\")\n",
    "# remove multiple spaces with single space\n",
    "data_task2.text = data_task2.text.str.replace('\\s+', ' ')\n",
    "#remove all single characters\n",
    "data_task2.text = data_task2.text.str.replace(r'\\s+[a-zA-Z]\\s+', '')\n",
    "data_task2['tokens'] = data_task2['text'].map(tokenize)\n",
    "data_task2['lemma'] = data_task2['tokens'].map(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56e4557f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>text</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>@@14767805</td>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[we, also, know, that, they, can, benefit, by,...</td>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279</td>\n",
       "      <td>@@7896098</td>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[pope, francis, washed, and, kissed, the, feet...</td>\n",
       "      <td>pope francis washed and kissed the foot of mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8330</td>\n",
       "      <td>@@17252299</td>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[many, refugees, do, n, t, want, to, be, reset...</td>\n",
       "      <td>many refugee do n t want to be resettled anywh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4063</td>\n",
       "      <td>@@3002894</td>\n",
       "      <td>\"budding chefs like \"\" fred \"\" \"\" winston \"\" a...</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ie</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1]</td>\n",
       "      <td>[budding, chefs, like, fred, winston, and, ang...</td>\n",
       "      <td>budding chef like fred winston and angela in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4089</td>\n",
       "      <td>@@25597822</td>\n",
       "      <td>\"in90-degree view of his constituency one can ...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>pk</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[in90, degree, view, of, his, constituency, on...</td>\n",
       "      <td>in90 degree view of his constituency one can s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  par_id      art_id                                               text  \\\n",
       "0   4046  @@14767805  we also know that they can benefit by receivin...   \n",
       "1   1279   @@7896098  pope francis washed and kissed the feet of mus...   \n",
       "2   8330  @@17252299  many refugees do n't want to be resettled anyw...   \n",
       "3   4063   @@3002894  \"budding chefs like \"\" fred \"\" \"\" winston \"\" a...   \n",
       "4   4089  @@25597822  \"in90-degree view of his constituency one can ...   \n",
       "\n",
       "    keyword country                  label  \\\n",
       "0  hopeless      us  [1, 0, 0, 0, 0, 0, 1]   \n",
       "1   refugee      ng  [0, 0, 0, 0, 1, 0, 0]   \n",
       "2   refugee      ng  [0, 0, 0, 1, 0, 0, 0]   \n",
       "3   in-need      ie  [1, 1, 1, 0, 0, 0, 1]   \n",
       "4  homeless      pk  [0, 0, 0, 0, 0, 0, 1]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [we, also, know, that, they, can, benefit, by,...   \n",
       "1  [pope, francis, washed, and, kissed, the, feet...   \n",
       "2  [many, refugees, do, n, t, want, to, be, reset...   \n",
       "3  [budding, chefs, like, fred, winston, and, ang...   \n",
       "4  [in90, degree, view, of, his, constituency, on...   \n",
       "\n",
       "                                               lemma  \n",
       "0  we also know that they can benefit by receivin...  \n",
       "1  pope francis washed and kissed the foot of mus...  \n",
       "2  many refugee do n t want to be resettled anywh...  \n",
       "3  budding chef like fred winston and angela in t...  \n",
       "4  in90 degree view of his constituency one can s...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a686eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_para = data_task2['lemma']\n",
    "vectorizer_task2 = TfidfVectorizer(use_idf=True,stop_words=stopwords.words('english'), min_df=7, lowercase=True, ngram_range=(1, 2))\n",
    "processed_features_task2 = vectorizer_task2.fit_transform(data_para).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03e939ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 696)\n"
     ]
    }
   ],
   "source": [
    "print(processed_features_task2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "22615dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 3146)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_task2 = processed_features_task2[0:993,:]\n",
    "train_data_task2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ec73a83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3832, 3146)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_task2 = processed_features_task2[993:,:]\n",
    "test_data_task2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120f7f1",
   "metadata": {},
   "source": [
    "### task2 training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b515809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((993,7))\n",
    "for i in range(993):\n",
    "    y[i] = data_task2['label'][i]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90b7d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train12, X_test12, y_train12, y_test12 = train_test_split(processed_features_task2, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be86302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.11557788944723618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.52      0.42        42\n",
      "           1       0.71      0.66      0.68        98\n",
      "           2       0.38      0.33      0.35        46\n",
      "           3       0.47      0.49      0.48        51\n",
      "           4       0.48      0.59      0.53        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.76      0.79      0.78       136\n",
      "\n",
      "   micro avg       0.58      0.61      0.60       421\n",
      "   macro avg       0.45      0.48      0.46       421\n",
      "weighted avg       0.59      0.61      0.60       421\n",
      " samples avg       0.61      0.63      0.58       421\n",
      "\n",
      "F1_score per class: [0.41904762 0.68421053 0.35294118 0.48076923 0.52873563 0.\n",
      " 0.77697842]\n",
      "Macro F1_score: 0.46324037172190324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression for multilabel data\n",
    "Logit_multilabel = LogisticRegression(random_state=1, class_weight=\"balanced\")\n",
    "multi_target_logit = MultiOutputClassifier(Logit_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76ba16e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.17587939698492464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.02      0.04        42\n",
      "           1       0.71      0.66      0.69        98\n",
      "           2       1.00      0.04      0.08        46\n",
      "           3       0.79      0.22      0.34        51\n",
      "           4       0.53      0.21      0.30        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.70      0.93      0.79       136\n",
      "\n",
      "   micro avg       0.70      0.51      0.59       421\n",
      "   macro avg       0.58      0.30      0.32       421\n",
      "weighted avg       0.68      0.51      0.50       421\n",
      " samples avg       0.72      0.56      0.59       421\n",
      "\n",
      "F1_score per class: [0.04444444 0.68783069 0.08333333 0.33846154 0.2962963  0.\n",
      " 0.79495268]\n",
      "Macro F1_score: 0.32075985453633044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_multilabel = SVC(kernel=\"linear\")\n",
    "multi_target_logit = MultiOutputClassifier(svm_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7103099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.11055276381909548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.29      0.26        42\n",
      "           1       0.64      0.51      0.57        98\n",
      "           2       0.24      0.22      0.23        46\n",
      "           3       0.31      0.27      0.29        51\n",
      "           4       0.40      0.36      0.38        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.72      0.79      0.76       136\n",
      "\n",
      "   micro avg       0.51      0.49      0.50       421\n",
      "   macro avg       0.36      0.35      0.35       421\n",
      "weighted avg       0.51      0.49      0.50       421\n",
      " samples avg       0.52      0.53      0.48       421\n",
      "\n",
      "F1_score per class: [0.26086957 0.56818182 0.22727273 0.29166667 0.37837838 0.\n",
      " 0.75524476]\n",
      "Macro F1_score: 0.35451627299453387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "decision_multilabel = DecisionTreeClassifier()\n",
    "multi_target_logit = MultiOutputClassifier(decision_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88921362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.17587939698492464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.10      0.12        42\n",
      "           1       0.76      0.52      0.62        98\n",
      "           2       0.27      0.13      0.18        46\n",
      "           3       0.48      0.22      0.30        51\n",
      "           4       0.43      0.23      0.30        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.73      0.87      0.79       136\n",
      "\n",
      "   micro avg       0.63      0.47      0.54       421\n",
      "   macro avg       0.41      0.29      0.33       421\n",
      "weighted avg       0.56      0.47      0.50       421\n",
      " samples avg       0.62      0.52      0.52       421\n",
      "\n",
      "F1_score per class: [0.12307692 0.61818182 0.17647059 0.2972973  0.3        0.\n",
      " 0.79194631]\n",
      "Macro F1_score: 0.329567562216595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bag_multilabel = BaggingClassifier()\n",
    "multi_target_logit = MultiOutputClassifier(bag_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79231135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.18592964824120603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.05      0.08        42\n",
      "           1       0.89      0.56      0.69        98\n",
      "           2       0.67      0.04      0.08        46\n",
      "           3       0.89      0.16      0.27        51\n",
      "           4       0.50      0.13      0.20        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.71      0.98      0.82       136\n",
      "\n",
      "   micro avg       0.73      0.49      0.58       421\n",
      "   macro avg       0.56      0.27      0.31       421\n",
      "weighted avg       0.69      0.49      0.49       421\n",
      " samples avg       0.75      0.55      0.59       421\n",
      "\n",
      "F1_score per class: [0.08       0.6875     0.08163265 0.26666667 0.20408163 0.\n",
      " 0.82098765]\n",
      "Macro F1_score: 0.30583837238599143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bag_multilabel = RandomForestClassifier()\n",
    "multi_target_logit = MultiOutputClassifier(bag_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbdf5da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.1708542713567839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.05      0.07        42\n",
      "           1       0.75      0.49      0.59        98\n",
      "           2       0.29      0.09      0.13        46\n",
      "           3       0.62      0.16      0.25        51\n",
      "           4       0.62      0.26      0.36        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.70      0.94      0.81       136\n",
      "\n",
      "   micro avg       0.65      0.48      0.55       421\n",
      "   macro avg       0.45      0.28      0.32       421\n",
      "weighted avg       0.58      0.48      0.48       421\n",
      " samples avg       0.68      0.52      0.55       421\n",
      "\n",
      "F1_score per class: [0.07142857 0.59259259 0.13333333 0.25       0.36363636 0.\n",
      " 0.80503145]\n",
      "Macro F1_score: 0.3165746153616773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bag_multilabel = GradientBoostingClassifier()\n",
    "multi_target_logit = MultiOutputClassifier(bag_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9526fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.135678391959799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.17      0.19        42\n",
      "           1       0.72      0.59      0.65        98\n",
      "           2       0.50      0.11      0.18        46\n",
      "           3       0.59      0.25      0.36        51\n",
      "           4       0.53      0.26      0.34        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.71      0.92      0.80       136\n",
      "\n",
      "   micro avg       0.64      0.52      0.57       421\n",
      "   macro avg       0.47      0.33      0.36       421\n",
      "weighted avg       0.59      0.52      0.52       421\n",
      " samples avg       0.65      0.55      0.56       421\n",
      "\n",
      "F1_score per class: [0.18918919 0.64804469 0.17857143 0.35616438 0.34482759 0.\n",
      " 0.79872204]\n",
      "Macro F1_score: 0.3593599035707176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bag_multilabel = xgboost.XGBClassifier()\n",
    "multi_target_logit = MultiOutputClassifier(bag_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426b97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be410547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c4e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a270aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492bb739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8ca4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c895a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "402ace44",
   "metadata": {},
   "source": [
    "### Train on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4ffaaef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic regression for multilabel data\n",
    "Logit_multilabel = LogisticRegression(random_state=1, class_weight=\"balanced\")\n",
    "multi_target_logit = MultiOutputClassifier(Logit_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(train_data_task2, y)\n",
    "pred_y_logit = multi_target_logit.predict(test_data_task2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "baffa5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8d237bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_task2_pred = pd.DataFrame(pred_y_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2f1d2f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6\n",
       "0     0  0  0  0  0  0  1\n",
       "1     1  0  0  1  0  0  0\n",
       "2     1  1  0  1  0  0  1\n",
       "3     0  1  0  0  0  0  0\n",
       "4     0  0  0  0  0  0  1\n",
       "...  .. .. .. .. .. .. ..\n",
       "3827  0  0  0  0  0  0  1\n",
       "3828  0  1  0  0  1  0  1\n",
       "3829  0  1  0  0  0  0  0\n",
       "3830  0  1  0  0  0  0  0\n",
       "3831  1  1  0  1  0  0  1\n",
       "\n",
       "[3832 rows x 7 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_task2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "44fedbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_logit= pred_y_logit.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d5fdff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5d415eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 1, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 1],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [1, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 1, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " ...]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_logit_list = pred_y_logit.tolist()\n",
    "pred_y_logit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0f2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "da59b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_task2_pd = pd.DataFrame(pred_y_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9164d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6\n",
       "0     0  0  0  0  0  0  1\n",
       "1     1  0  0  1  0  0  0\n",
       "2     1  1  0  1  0  0  1\n",
       "3     0  1  0  0  0  0  0\n",
       "4     0  0  0  0  0  0  1\n",
       "...  .. .. .. .. .. .. ..\n",
       "3827  0  0  0  0  0  0  1\n",
       "3828  0  1  0  0  1  0  1\n",
       "3829  0  1  0  0  0  0  0\n",
       "3830  0  1  0  0  0  0  0\n",
       "3831  1  1  0  1  0  0  1\n",
       "\n",
       "[3832 rows x 7 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_task2_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "8a9016b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_task2_pd.to_csv('C:\\\\Users\\\\Bichu George\\\\Desktop\\\\task2.txt',index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808f5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c359175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf1401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b30555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56995d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56d33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4400da7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>text</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>@@14767805</td>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279</td>\n",
       "      <td>@@7896098</td>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8330</td>\n",
       "      <td>@@17252299</td>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ng</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4063</td>\n",
       "      <td>@@3002894</td>\n",
       "      <td>\"budding chefs , like \"\" fred \"\" , \"\" winston ...</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ie</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4089</td>\n",
       "      <td>@@25597822</td>\n",
       "      <td>\"in a 90-degree view of his constituency , one...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>pk</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>432</td>\n",
       "      <td>@@15802146</td>\n",
       "      <td>he depicts demonstrations by refugees at the b...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>nz</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4177</td>\n",
       "      <td>@@930041</td>\n",
       "      <td>the word of god is truth that 's living and ab...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3963</td>\n",
       "      <td>@@18867357</td>\n",
       "      <td>chantelle owens , mrs planet 2016 , hosted the...</td>\n",
       "      <td>in-need</td>\n",
       "      <td>za</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001</td>\n",
       "      <td>@@14012804</td>\n",
       "      <td>t is remiss not to mention here that not all s...</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>tz</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>369</td>\n",
       "      <td>@@15636898</td>\n",
       "      <td>\"\"\" people do n't understand the hurt , people...</td>\n",
       "      <td>women</td>\n",
       "      <td>ie</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  par_id      art_id                                               text  \\\n",
       "0   4046  @@14767805  we also know that they can benefit by receivin...   \n",
       "1   1279   @@7896098  pope francis washed and kissed the feet of mus...   \n",
       "2   8330  @@17252299  many refugees do n't want to be resettled anyw...   \n",
       "3   4063   @@3002894  \"budding chefs , like \"\" fred \"\" , \"\" winston ...   \n",
       "4   4089  @@25597822  \"in a 90-degree view of his constituency , one...   \n",
       "5    432  @@15802146  he depicts demonstrations by refugees at the b...   \n",
       "6   4177    @@930041  the word of god is truth that 's living and ab...   \n",
       "7   3963  @@18867357  chantelle owens , mrs planet 2016 , hosted the...   \n",
       "8   2001  @@14012804  t is remiss not to mention here that not all s...   \n",
       "9    369  @@15636898  \"\"\" people do n't understand the hurt , people...   \n",
       "\n",
       "         keyword country                  label  \n",
       "0       hopeless      us  [1, 0, 0, 0, 0, 0, 1]  \n",
       "1        refugee      ng  [0, 0, 0, 0, 1, 0, 0]  \n",
       "2        refugee      ng  [0, 0, 0, 1, 0, 0, 0]  \n",
       "3        in-need      ie  [1, 1, 1, 0, 0, 0, 1]  \n",
       "4       homeless      pk  [0, 0, 0, 0, 0, 0, 1]  \n",
       "5        refugee      nz  [0, 1, 0, 0, 0, 0, 0]  \n",
       "6       hopeless      us  [0, 1, 0, 0, 0, 0, 1]  \n",
       "7        in-need      za  [0, 1, 0, 0, 1, 0, 1]  \n",
       "8  poor-families      tz  [0, 0, 0, 1, 0, 0, 0]  \n",
       "9          women      ie  [1, 1, 0, 1, 0, 0, 1]  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "064b7490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "par_id     0\n",
       "art_id     0\n",
       "text       0\n",
       "keyword    0\n",
       "country    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffbdff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_task2 = data_task2.drop(['art_id'], axis=1)  # dropping unnecesary column\n",
    "data_task2 = data_task2.drop(['par_id'], axis=1)  # dropping unnecesary column\n",
    "data_task2 = data_task2.drop(['country'], axis=1)  # dropping unnecesary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f66beb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we also know that they can benefit by receivin...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pope francis washed and kissed the feet of mus...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many refugees do n't want to be resettled anyw...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"budding chefs , like \"\" fred \"\" , \"\" winston ...</td>\n",
       "      <td>in-need</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"in a 90-degree view of his constituency , one...</td>\n",
       "      <td>homeless</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he depicts demonstrations by refugees at the b...</td>\n",
       "      <td>refugee</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the word of god is truth that 's living and ab...</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chantelle owens , mrs planet 2016 , hosted the...</td>\n",
       "      <td>in-need</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t is remiss not to mention here that not all s...</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"\"\" people do n't understand the hurt , people...</td>\n",
       "      <td>women</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        keyword  \\\n",
       "0  we also know that they can benefit by receivin...       hopeless   \n",
       "1  pope francis washed and kissed the feet of mus...        refugee   \n",
       "2  many refugees do n't want to be resettled anyw...        refugee   \n",
       "3  \"budding chefs , like \"\" fred \"\" , \"\" winston ...        in-need   \n",
       "4  \"in a 90-degree view of his constituency , one...       homeless   \n",
       "5  he depicts demonstrations by refugees at the b...        refugee   \n",
       "6  the word of god is truth that 's living and ab...       hopeless   \n",
       "7  chantelle owens , mrs planet 2016 , hosted the...        in-need   \n",
       "8  t is remiss not to mention here that not all s...  poor-families   \n",
       "9  \"\"\" people do n't understand the hurt , people...          women   \n",
       "\n",
       "                   label  \n",
       "0  [1, 0, 0, 0, 0, 0, 1]  \n",
       "1  [0, 0, 0, 0, 1, 0, 0]  \n",
       "2  [0, 0, 0, 1, 0, 0, 0]  \n",
       "3  [1, 1, 1, 0, 0, 0, 1]  \n",
       "4  [0, 0, 0, 0, 0, 0, 1]  \n",
       "5  [0, 1, 0, 0, 0, 0, 0]  \n",
       "6  [0, 1, 0, 0, 0, 0, 1]  \n",
       "7  [0, 1, 0, 0, 1, 0, 1]  \n",
       "8  [0, 0, 0, 1, 0, 0, 0]  \n",
       "9  [1, 1, 0, 1, 0, 0, 1]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc59401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-2c852516f30a>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace('[#,@,&]', '')\n",
      "<ipython-input-27-2c852516f30a>:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace(' \\d+ ','')\n",
      "<ipython-input-27-2c852516f30a>:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace('w{3}','')\n",
      "<ipython-input-27-2c852516f30a>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace(\"http\\S+\", \"\")\n",
      "<ipython-input-27-2c852516f30a>:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace('\\s+', ' ')\n",
      "<ipython-input-27-2c852516f30a>:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_task2.text = data_task2.text.str.replace(r'\\s+[a-zA-Z]\\s+', '')\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(x)\n",
    "\n",
    "\n",
    "def lemmatize(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "#  Preprocess train dataset\n",
    "# remove special characters from text column\n",
    "data_task2.text = data_task2.text.str.replace('[#,@,&]', '')\n",
    "# Remove digits\n",
    "data_task2.text = data_task2.text.str.replace(' \\d+ ','')\n",
    "#Remove www\n",
    "data_task2.text = data_task2.text.str.replace('w{3}','')\n",
    "# remove urls\n",
    "data_task2.text = data_task2.text.str.replace(\"http\\S+\", \"\")\n",
    "# remove multiple spaces with single space\n",
    "data_task2.text = data_task2.text.str.replace('\\s+', ' ')\n",
    "#remove all single characters\n",
    "data_task2.text = data_task2.text.str.replace(r'\\s+[a-zA-Z]\\s+', '')\n",
    "data_task2['tokens'] = data_task2['text'].map(tokenize)\n",
    "data_task2['lemma'] = data_task2['tokens'].map(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e83e8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_task2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dcdd490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_para12 = data_task2['lemma']\n",
    "vectorizer12 = TfidfVectorizer(use_idf=True, stop_words=stopwords.words('english'), min_df=7, lowercase=True, ngram_range=(1, 2))\n",
    "processed_features12 = vectorizer12.fit_transform(data_para12).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f369acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 696)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_features12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "491af9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((993,7))\n",
    "for i in range(993):\n",
    "    y[i] = data_task2['label'][i]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7249652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train12, X_test12, y_train12, y_test12 = train_test_split(processed_features12, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53c42f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.11557788944723618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.52      0.42        42\n",
      "           1       0.71      0.66      0.68        98\n",
      "           2       0.38      0.33      0.35        46\n",
      "           3       0.47      0.49      0.48        51\n",
      "           4       0.48      0.59      0.53        39\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.76      0.79      0.78       136\n",
      "\n",
      "   micro avg       0.58      0.61      0.60       421\n",
      "   macro avg       0.45      0.48      0.46       421\n",
      "weighted avg       0.59      0.61      0.60       421\n",
      " samples avg       0.61      0.63      0.58       421\n",
      "\n",
      "F1_score per class: [0.41904762 0.68421053 0.35294118 0.48076923 0.52873563 0.\n",
      " 0.77697842]\n",
      "Macro F1_score: 0.46324037172190324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bichu George\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression for multilabel data\n",
    "Logit_multilabel = LogisticRegression(random_state=1, class_weight=\"balanced\")\n",
    "multi_target_logit = MultiOutputClassifier(Logit_multilabel, n_jobs=-1)\n",
    "multi_target_logit.fit(X_train12, y_train12)\n",
    "pred_y_logit = multi_target_logit.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_logit)}\")\n",
    "print(classification_report(y_test12,pred_y_logit))\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_logit,average=None)}\")\n",
    "print(f\"Macro F1_score: {f1_score(y_test12, pred_y_logit,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08bb763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[116,  41],\n",
       "        [ 20,  22]],\n",
       "\n",
       "       [[ 74,  27],\n",
       "        [ 33,  65]],\n",
       "\n",
       "       [[129,  24],\n",
       "        [ 31,  15]],\n",
       "\n",
       "       [[120,  28],\n",
       "        [ 26,  25]],\n",
       "\n",
       "       [[135,  25],\n",
       "        [ 16,  23]],\n",
       "\n",
       "       [[185,   5],\n",
       "        [  9,   0]],\n",
       "\n",
       "       [[ 29,  34],\n",
       "        [ 28, 108]]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_test12, pred_y_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12ae0d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.17587939698492464\n",
      "F1_score per class: [0.0754717  0.66272189 0.08333333 0.20689655 0.17777778 0.\n",
      " 0.8115016 ]\n",
      "F1_score: 0.28824326455481003\n"
     ]
    }
   ],
   "source": [
    "## Random forest for multi label data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(random_state=1, class_weight=\"balanced\")\n",
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "multi_target_forest.fit(X_train12, y_train12)\n",
    "pred_y_forest = multi_target_forest.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_forest)}\")\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_forest,average=None)}\")\n",
    "print(f\"F1_score: {f1_score(y_test12, pred_y_forest,average='macro')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84cf969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[148,   9],\n",
       "        [ 40,   2]],\n",
       "\n",
       "       [[ 86,  15],\n",
       "        [ 42,  56]],\n",
       "\n",
       "       [[153,   0],\n",
       "        [ 44,   2]],\n",
       "\n",
       "       [[147,   1],\n",
       "        [ 45,   6]],\n",
       "\n",
       "       [[158,   2],\n",
       "        [ 35,   4]],\n",
       "\n",
       "       [[190,   0],\n",
       "        [  9,   0]],\n",
       "\n",
       "       [[ 13,  50],\n",
       "        [  9, 127]]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_test12, pred_y_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80f05e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.19095477386934673\n",
      "F1_score per class: [0.         0.70786517 0.04255319 0.14545455 0.         0.\n",
      " 0.80606061]\n",
      "F1_score: 0.24313335879197698\n"
     ]
    }
   ],
   "source": [
    "## Naive bayes\n",
    "model_Naive_multi = MultinomialNB()\n",
    "multi_Naive_multi = MultiOutputClassifier(model_Naive_multi, n_jobs=-1)\n",
    "multi_Naive_multi.fit(X_train12, y_train12)\n",
    "pred_y_naive = multi_Naive_multi.predict(X_test12)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test12, pred_y_naive)}\")\n",
    "print(f\"F1_score per class: {f1_score(y_test12, pred_y_naive,average=None)}\")\n",
    "print(f\"F1_score: {f1_score(y_test12, pred_y_naive,average='macro')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0982f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[157,   0],\n",
       "        [ 42,   0]],\n",
       "\n",
       "       [[ 84,  17],\n",
       "        [ 35,  63]],\n",
       "\n",
       "       [[153,   0],\n",
       "        [ 45,   1]],\n",
       "\n",
       "       [[148,   0],\n",
       "        [ 47,   4]],\n",
       "\n",
       "       [[160,   0],\n",
       "        [ 39,   0]],\n",
       "\n",
       "       [[190,   0],\n",
       "        [  9,   0]],\n",
       "\n",
       "       [[  2,  61],\n",
       "        [  3, 133]]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_test12, pred_y_naive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
